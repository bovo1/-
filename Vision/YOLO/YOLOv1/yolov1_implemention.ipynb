{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOaXdFWyxuh+f460a0qxqRM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d7f06228238475db03f23be0f92ff57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f3e0d76e07e427488d6833289a9216b",
              "IPY_MODEL_5db573aa165a4af18abb9e8787ba9aa1",
              "IPY_MODEL_4fd4a8b0aa3d453386e55a347e0e8cce"
            ],
            "layout": "IPY_MODEL_e4c41b2155d44a70862aa7a110f122bb"
          }
        },
        "9f3e0d76e07e427488d6833289a9216b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21e74a05b04041d9a18a24ffd27f3dbf",
            "placeholder": "​",
            "style": "IPY_MODEL_443cfa88d5bd4c2db86449575302c67f",
            "value": "train:  70%"
          }
        },
        "5db573aa165a4af18abb9e8787ba9aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_586ee40be1134431b6a9fb3b9aef69c8",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52adfc77f2e146f89518b996fef379b1",
            "value": 7
          }
        },
        "4fd4a8b0aa3d453386e55a347e0e8cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a023532b3f402eaf2911760cb0a9e5",
            "placeholder": "​",
            "style": "IPY_MODEL_6e81bb29b5fe41058e83874298926ed9",
            "value": " 7/10 [7:14:40&lt;3:06:38, 3732.79s/it]"
          }
        },
        "e4c41b2155d44a70862aa7a110f122bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21e74a05b04041d9a18a24ffd27f3dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "443cfa88d5bd4c2db86449575302c67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "586ee40be1134431b6a9fb3b9aef69c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52adfc77f2e146f89518b996fef379b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68a023532b3f402eaf2911760cb0a9e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e81bb29b5fe41058e83874298926ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bovo1/model_implemention/blob/main/Vision/YOLO/YOLOv1/yolov1_implemention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeudkhmGM6KM",
        "outputId": "11c7d290-9990-41c1-e634-cccbce3f20bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install xmltodict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import VOCDetection\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import xmltodict\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLO v1 에서는 VOCDetection 데이터를 사용합니다.\n",
        "데이터를 모델에 사용하기 위해 전처리를 진행합니다."
      ],
      "metadata": {
        "id": "gWgF4tI0NfpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\",\n",
        "           \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
        "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
        "           \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]"
      ],
      "metadata": {
        "id": "8NCJwZvoPkdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Pascal_data(VOCDetection):\n",
        "  def __getitem__(self, idx):\n",
        "    img = Image.open(self.images[idx]).convert(\"RGB\").resize((448,448))\n",
        "    transform_img = transforms.Compose([transforms.PILToTensor(),\n",
        "                                          transforms.Resize((448,448))])\n",
        "    transformed_img = torch.divide(transform_img(img), 255)\n",
        "\n",
        "    target = xmltodict.parse(open(self.annotations[idx]).read())\n",
        "    image_height = float(target['annotation']['size']['height'])\n",
        "    image_width = float(target['annotation']['size']['width'])\n",
        "    label = torch.zeros((7,7,30))\n",
        "\n",
        "    #bounding box\n",
        "    try:\n",
        "      for obj in target['annotation']['object']:\n",
        "        class_idx = classes.index(obj['name'].lower())\n",
        "\n",
        "        x_min = float(obj['bndbox']['xmin'])\n",
        "        y_min = float(obj['bndbox']['ymin'])\n",
        "        x_max = float(obj['bndbox']['xmax'])\n",
        "        y_max = float(obj['bndbox']['ymax'])\n",
        "\n",
        "        x_min = float((448.0/image_width)*x_min)\n",
        "        y_min = float((448.0/image_height)*y_min)\n",
        "        x_max = float((448.0/image_width)*x_max)\n",
        "        y_max = float((448.0/image_height)*y_max)\n",
        "\n",
        "        #yolo가 요구하는 데이터는 x,y,w,h\n",
        "        x = (x_min + x_max) / 2.0\n",
        "        y = (y_min + y_max) / 2.0\n",
        "        w = x_max - x_min\n",
        "        h = y_max - y_min\n",
        "\n",
        "        #x,y가 속한 영역(cell)\n",
        "        x_cell = int(x/64)\n",
        "        y_cell = int(x/64)\n",
        "        x_incell = float((x-(x_cell*64))/64)\n",
        "        y_incell = float((y-(y_cell*64))/64)\n",
        "\n",
        "        w = w/448.0\n",
        "        h = h/448.0\n",
        "\n",
        "        label[y_cell][x_cell][0] = x_incell\n",
        "        label[y_cell][x_cell][1] = y_incell\n",
        "        label[y_cell][x_cell][2] = w\n",
        "        label[y_cell][x_cell][3] = h\n",
        "        label[y_cell][x_cell][4] = 1.0\n",
        "        label[y_cell][x_cell][class_idx+10] = 1.0\n",
        "\n",
        "    except TypeError as e:\n",
        "      class_idx = classes.index(target['annotation']['object']['name'].lower())\n",
        "\n",
        "      x_min = float(target['annotation']['object']['bndbox']['xmin'])\n",
        "      y_min = float(target['annotation']['object']['bndbox']['ymin'])\n",
        "      x_max = float(target['annotation']['object']['bndbox']['xmax'])\n",
        "      y_max = float(target['annotation']['object']['bndbox']['ymax'])\n",
        "\n",
        "      x_min = float((448.0/image_width)*x_min)\n",
        "      y_min = float((448.0/image_height)*y_min)\n",
        "      x_max = float((448.0/image_width)*x_max)\n",
        "      y_max = float((448.0/image_height)*y_max)\n",
        "\n",
        "          #yolo가 요구하는 데이터는 x,y,w,h\n",
        "      x = (x_min + x_max) / 2.0\n",
        "      y = (y_min + y_max) / 2.0\n",
        "      w = x_max - x_min\n",
        "      h = y_max - y_min\n",
        "\n",
        "          #x,y가 속한 영역(cell)\n",
        "      x_cell = int(x/64)\n",
        "      y_cell = int(x/64)\n",
        "      x_incell = float((x-(x_cell*64))/64)\n",
        "      y_incell = float((y-(y_cell*64))/64)\n",
        "\n",
        "      w = w/448.0\n",
        "      h = h/448.0\n",
        "\n",
        "      label[y_cell][x_cell][0] = x_incell\n",
        "      label[y_cell][x_cell][1] = y_incell\n",
        "      label[y_cell][x_cell][2] = w\n",
        "      label[y_cell][x_cell][3] = h\n",
        "      label[y_cell][x_cell][4] = 1.0\n",
        "      label[y_cell][x_cell][class_idx+10] = 1.0\n",
        "    return transformed_img, torch.tensor(label)"
      ],
      "metadata": {
        "id": "xpZigaJCNduL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rUDf-cMQ9Ua8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델"
      ],
      "metadata": {
        "id": "sRSu7ui6mKDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLOv1(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(YOLOv1, self).__init__()\n",
        "    self.darknet = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
        "\n",
        "        nn.Conv2d(64,192,3, padding=1),\n",
        "        nn.BatchNorm2d(192),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.MaxPool2d((2,2), 2),\n",
        "\n",
        "        nn.Conv2d(192, 128, 1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(128, 256, 3,padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(256,256,1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(256,512,3,padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.MaxPool2d((2,2), 2),\n",
        "\n",
        "        nn.Conv2d(512, 256,1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(256,512,3,padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(512, 256,1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(256,512,3,padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(512, 256,1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(256,512,3,padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(512, 256,1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(256,512,3,padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(512,512,1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(512,1024,3,padding=1),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.MaxPool2d((2,2),2),\n",
        "\n",
        "        nn.Conv2d(1024,512,1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(512,1024,3,padding=1),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(1024,512,1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Conv2d(512,1024,3,padding=1),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(1024,1024,3,padding=1),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(1024,1024,3,stride=2, padding=1),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(1024,1024,3,padding=1),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Conv2d(1024,1024,3,padding=1),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.LeakyReLU(0.1))\n",
        "\n",
        "    self.head = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(7*7*1024, 4096),\n",
        "      nn.Dropout(),\n",
        "      nn.LeakyReLU(0.1),\n",
        "      nn.Linear(4096,1470))\n",
        "\n",
        "    for m in self.darknet.modules():\n",
        "    \tif isinstance(m, nn.Conv2d):\n",
        "\t\t    nn.init.normal_(m.weight, mean=0, std=0.01)\n",
        "\n",
        "    for m in self.head.modules():\n",
        "      if isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
        "\n",
        "  def forward(self, x):\n",
        "    nn.Flatten()\n",
        "    out = self.darknet(x)\n",
        "    out = self.head(out)\n",
        "    out = torch.reshape(out, (-1,7,7,30))\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "qNdOT2gz7NgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loss, optimizer, epochs, data_loader):\n",
        "  for epoch in tqdm(range(epochs), desc='train', mininterval=0.01):\n",
        "    count=0\n",
        "    #print(\"epochs: \", epoch, \"/\", epochs)\n",
        "    for inputs, labels in data_loader:\n",
        "      #pbar = tqdm()\n",
        "      count += 1\n",
        "\n",
        "      #print(\"<optimizer_zero_grading>\")\n",
        "      optimizer.zero_grad()\n",
        "      #print(\"<inputs in model>\")\n",
        "      outputs = model(inputs)\n",
        "      #print(\"<calculate loss>\")\n",
        "      loss_fn = loss(outputs, labels)\n",
        "      #print(\"<backward>\")\n",
        "      loss_fn.requires_grad_(True)\n",
        "      loss_fn.backward()\n",
        "      #print(\"loss: \", loss_fn, loss_fn.item())\n",
        "      #print(\"<step>\")\n",
        "      optimizer.step()\n",
        "      if count % 10 == 0:\n",
        "        print(\"repeat \", count, \"/\", len(data_loader), \"\\n\"\n",
        "              \"loss: \", loss_fn.item())\n",
        "    print('Epoch:', epoch+1, '|', 'loss:', loss_fn.item())"
      ],
      "metadata": {
        "id": "vL_f--wGZ4XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(y_pred, y_true):\n",
        "  noobj = 0.5\n",
        "  coord = 5\n",
        "  batch_loss = 0\n",
        "  count = len(y_true)\n",
        "  #print('y_pred: ', y_pred.shape)\n",
        "  #print('y_true: ', y_true.shape)\n",
        "  for i in range(0, len(y_true)):\n",
        "    true_unit = y_true[i].detach().requires_grad_(True)\n",
        "    pred_unit = y_pred[i].detach().requires_grad_(True)\n",
        "    true_unit = torch.reshape(true_unit, [49,30])\n",
        "    pred_unit = torch.reshape(pred_unit, [49,30])\n",
        "    loss = 0\n",
        "    #print('pred_unit: ', pred_unit.shape)\n",
        "    #print('true_unit: ', true_unit.shape)\n",
        "    for j in range(len(true_unit)):\n",
        "      bounding_box1_xywh = pred_unit[j,:4].detach().requires_grad_(True)\n",
        "      bounding_box1_confidence = pred_unit[j, 4].detach().requires_grad_(True)\n",
        "      bounding_box2_xywh = pred_unit[j, 5:9].detach().requires_grad_(True)\n",
        "      bounding_box2_confidence = pred_unit[j, 9].detach().requires_grad_(True)\n",
        "      pred_class = pred_unit[j, 10:].detach().requires_grad_(True)\n",
        "      #print('bbox1_xywh: ', bounding_box1_xywh)\n",
        "      #print('bbox1_confidence: ', bounding_box1_confidence)\n",
        "      true_bbox1 = true_unit[j, :4].detach().requires_grad_(True)\n",
        "      true_bbox1_confidence = true_unit[4].detach().requires_grad_(True)\n",
        "      true_bbox2 = true_unit[j, 5:9].detach().requires_grad_(True)\n",
        "      true_bbox2_confidence = true_unit[j, 9].detach().requires_grad_(True)\n",
        "      true_class = true_unit[j, 10:].detach().requires_grad_(True)\n",
        "      #print('true_bbox1: ', true_bbox1.shape)\n",
        "      #print('true_bbox2: ', true_bbox2.shape)\n",
        "      bbox1_pred_info = bounding_box1_xywh.detach().numpy()\n",
        "      bbox2_pred_info = bounding_box2_xywh.detach().numpy()\n",
        "      bbox1_true_info = true_bbox1.detach().numpy()\n",
        "      bbox2_true_info = true_bbox2.detach().numpy()\n",
        "      #print('bbox1_info: ', bbox1_pred_info)\n",
        "      #print('bbox1[2]: ', bbox1_pred_info[2])\n",
        "      #print('bbox2_info: ', bbox2_pred_info)\n",
        "      #print('bbox1_true_info: ', bbox1_true_info)\n",
        "      #print('bbox2_true_info: ', bbox2_true_info)\n",
        "\n",
        "      bbox1_pred_area = bbox1_pred_info[2] * bbox1_pred_info[3]\n",
        "      bbox2_pred_area = bbox2_pred_info[2] * bbox2_pred_info[3]\n",
        "      bbox1_true_area = bbox1_true_info[2] * bbox1_true_info[3]\n",
        "      bbox2_true_area = bbox2_true_info[2] * bbox2_true_info[3]\n",
        "\n",
        "      #minx, miny, maxx, maxy\n",
        "      bbox1_pred_mM = np.asarray([bbox1_pred_info[0]-0.5*bbox1_pred_info[2], bbox1_pred_info[1]-0.5*bbox1_pred_info[3], bbox1_pred_info[0]+0.5*bbox1_pred_info[2], bbox1_pred_info[1]+0.5*bbox1_pred_info[3]])\n",
        "      bbox2_pred_mM = np.asarray([bbox2_pred_info[0]-0.5*bbox2_pred_info[2], bbox2_pred_info[1]-0.5*bbox2_pred_info[3], bbox2_pred_info[0]+0.5*bbox2_pred_info[2], bbox2_pred_info[1]+0.5*bbox2_pred_info[3]])\n",
        "      bbox1_true_mM = np.asarray([bbox1_true_info[0]-0.5*bbox1_true_info[2], bbox1_true_info[1]-0.5*bbox1_true_info[3], bbox1_true_info[0]+0.5*bbox1_true_info[2], bbox1_true_info[1]+0.5*bbox1_true_info[3]])\n",
        "      bbox2_true_mM = np.asarray([bbox2_true_info[0]-0.5*bbox2_true_info[2], bbox2_true_info[1]-0.5*bbox2_true_info[3], bbox2_true_info[0]+0.5*bbox2_true_info[2], bbox2_true_info[1]+0.5*bbox2_true_info[3]])\n",
        "      #print('bbox1_true_mM',bbox1_true_mM)\n",
        "      #print('bbox2_true_mM', bbox2_true_mM)\n",
        "      #IOU 계산\n",
        "      def cal_IOU(pred_np, true_np):\n",
        "        if (np.all(pred_np[0]== 0) == True and np.all(pred_np[1]==0)==True and np.all(pred_np[2]==0)==True and np.all(pred_np[3]==0)==True) or ((np.all(true_np[0] == 0) == True) and np.all(true_np[1]==0)==True and np.all(true_np[2]==0)==True and np.all(true_np[3]==0)==True):\n",
        "          box_iou = 0\n",
        "        else:\n",
        "          #print('pred_np[0]: ',pred_np[0])\n",
        "          #print('true_np[0]: ', true_np[0])\n",
        "          #print(min(pred_np[0], true_np[0]))\n",
        "          union_min_x = min(pred_np[0], true_np[0])\n",
        "          union_min_y = min(pred_np[1], true_np[1])\n",
        "          union_max_x = max(pred_np[2], true_np[2])\n",
        "          union_max_y = max(pred_np[3], true_np[3])\n",
        "          union_box = [union_min_x, union_min_y, union_max_x, union_max_y]\n",
        "\n",
        "          intersection_min_x = max(pred_np[0], true_np[0])\n",
        "          intersection_min_y = min(pred_np[1], true_np[1])\n",
        "          intersection_max_x = min(pred_np[2], true_np[2])\n",
        "          intersection_max_y = max(pred_np[3], true_np[3])\n",
        "          intersection_box = [intersection_min_x, intersection_min_y, intersection_max_x, intersection_max_y]\n",
        "\n",
        "          union_area = abs(union_max_x - union_min_x) * abs(union_max_y - union_min_y)\n",
        "          intersection_area = abs(intersection_max_x - intersection_min_x) * abs(intersection_max_y - intersection_min_y)\n",
        "\n",
        "          box_iou = intersection_area / union_area\n",
        "        return box_iou\n",
        "\n",
        "      IOU_bbox1_1 = cal_IOU(bbox1_pred_mM, bbox1_true_mM)\n",
        "      IOU_bbox1_2 = cal_IOU(bbox1_pred_mM, bbox2_true_mM)\n",
        "      IOU_bbox2_1 = cal_IOU(bbox2_pred_mM, bbox1_true_mM)\n",
        "      IOU_bbox2_2 = cal_IOU(bbox2_pred_mM, bbox2_true_mM)\n",
        "\n",
        "      #print('IOU score: ',IOU_bbox1_1, IOU_bbox1_2, IOU_bbox2_1, IOU_bbox2_2)\n",
        "\n",
        "      if IOU_bbox1_1 > IOU_bbox1_2:\n",
        "        responsible_pred_bbox1 = {\"name\":\"IOU_bbox1_1\", \"iou_value\":IOU_bbox1_1, \"pred_coord\":bounding_box1_xywh, \"pred_confidence\":bounding_box1_confidence, \"true_coord\":true_bbox1, \"true_confidence\":true_bbox1_confidence}\n",
        "        unresponsible_pred_bbox1 = {\"name\":\"IOU_bbox1_2\", \"iou_value\":IOU_bbox1_2, \"pred_coord\":bounding_box1_xywh, \"pred_confidence\":bounding_box1_confidence, \"true_coord\":true_bbox2, \"true_confidence\":true_bbox2_confidence}\n",
        "      else:\n",
        "        responsible_pred_bbox1 = {\"name\":\"IOU_bbox1_2\", \"iou_value\":IOU_bbox1_2, \"pred_coord\":bounding_box1_xywh, \"pred_confidence\":bounding_box1_confidence, \"true_coord\":true_bbox2, \"true_confidence\":true_bbox2_confidence}\n",
        "        unresponsible_pred_bbox1 = {\"name\":\"IOU_bbox1_1\", \"iou_value\":IOU_bbox1_1, \"pred_coord\":bounding_box1_xywh, \"pred_confidence\":bounding_box1_confidence, \"true_coord\":true_bbox1, \"true_confidence\":true_bbox1_confidence}\n",
        "\n",
        "      responsible_pred_bbox1['unresponsible'] = unresponsible_pred_bbox1\n",
        "\n",
        "      if IOU_bbox2_1 > IOU_bbox2_2:\n",
        "        responsible_pred_bbox2 = {\"name\":\"IOU_bbox2_1\", \"iou_value\":IOU_bbox2_1, \"pred_coord\":bounding_box2_xywh, \"pred_confidence\":bounding_box2_confidence, \"true_coord\":true_bbox1, \"true_confidence\":true_bbox1_confidence}\n",
        "        unresponsible_pred_bbox2 = {\"name\":\"IOU_bbox2_2\", \"iou_value\":IOU_bbox2_2, \"pred_coord\":bounding_box2_xywh, \"pred_confidence\":bounding_box2_confidence, \"true_coord\":true_bbox2, \"true_confidence\":true_bbox2_confidence}\n",
        "      else:\n",
        "        responsible_pred_bbox2 = {\"name\":\"IOU_bbox2_2:\", \"iou_value\":IOU_bbox2_2, \"pred_coord\":bounding_box2_xywh, \"pred_confidence\":bounding_box2_confidence, \"true_coord\":true_bbox2, \"true_confidence\":true_bbox2_confidence}\n",
        "        unresponsible_pred_bbox2 = {\"name\":\"IOU_bbox2_1\", \"iou_value\":IOU_bbox2_1, \"pred_coord\":bounding_box2_xywh, \"pred_confidence\":bounding_box2_confidence, \"true_coord\":true_bbox1, \"true_confidence\":true_bbox1_confidence}\n",
        "\n",
        "      responsible_pred_bbox2['unresponsible'] = unresponsible_pred_bbox2\n",
        "\n",
        "      if responsible_pred_bbox1['iou_value'] > responsible_pred_bbox2['iou_value']:\n",
        "        high_iou_dict = copy.deepcopy(responsible_pred_bbox1)\n",
        "        low_iou_dict = copy.deepcopy(responsible_pred_bbox2)\n",
        "      else:\n",
        "        high_iou_dict = copy.deepcopy(responsible_pred_bbox2)\n",
        "        low_iou_dict = copy.deepcopy(responsible_pred_bbox1)\n",
        "      #print('high_iou_dict: ', high_iou_dict)\n",
        "      #print('low_iou_dict: ', low_iou_dict)\n",
        "      #Localization\n",
        "      hx_loss = torch.pow(torch.subtract(high_iou_dict['true_coord'][0], high_iou_dict['pred_coord'][0]), 2)\n",
        "      hy_loss = torch.pow(torch.subtract(high_iou_dict['true_coord'][1], high_iou_dict['pred_coord'][1]), 2)\n",
        "      hw_loss = torch.pow(torch.subtract(torch.sqrt(high_iou_dict['true_coord'][2]), torch.sqrt(high_iou_dict['pred_coord'][2])), 2)\n",
        "      hh_loss = torch.pow(torch.subtract(torch.sqrt(high_iou_dict['true_coord'][3]), torch.sqrt(high_iou_dict['pred_coord'][3])), 2)\n",
        "\n",
        "      hloss_xy = torch.add(hx_loss, hy_loss)\n",
        "      hloss_wh = torch.add(hw_loss, hh_loss)\n",
        "      hlocal_loss = torch.add(hloss_xy, hloss_wh)\n",
        "\n",
        "      #print('high_iou_loss_xy: ', hloss_xy)\n",
        "\n",
        "\n",
        "      if torch.isnan(hlocal_loss).detach().any() == True:\n",
        "        hlocal_loss = torch.zeros_like(hlocal_loss)\n",
        "      #print('high_iou_loss_wh: ', hloss_wh)\n",
        "      #print('high_iou_loss: ', hlocal_loss)\n",
        "      htrue_object = torch.ones_like(high_iou_dict['true_confidence'])\n",
        "      if np.all(high_iou_dict['true_coord'][0].detach().numpy() == 0) == True and np.all(high_iou_dict['true_coord'][1].detach().numpy() == 0) == True and np.all(high_iou_dict['true_coord'][2].detach().numpy()==0) == True and np.all(high_iou_dict['true_coord'][3].detach().numpy()==0) == True:\n",
        "        htrue_object = torch.zeros_like(high_iou_dict['true_confidence'])\n",
        "\n",
        "      hweighted_local_loss = torch.multiply(torch.multiply(hlocal_loss, coord), htrue_object)\n",
        "\n",
        "      lx_loss = torch.pow(torch.subtract(low_iou_dict['true_coord'][0], low_iou_dict['pred_coord'][0]), 2)\n",
        "      ly_loss = torch.pow(torch.subtract(low_iou_dict['true_coord'][1], low_iou_dict['pred_coord'][1]), 2)\n",
        "      lw_loss = torch.pow(torch.subtract(torch.sqrt(low_iou_dict['true_coord'][2]), torch.sqrt(low_iou_dict['pred_coord'][2])), 2)\n",
        "      lh_loss = torch.pow(torch.subtract(torch.sqrt(low_iou_dict['true_coord'][3]), torch.sqrt(low_iou_dict['pred_coord'][3])), 2)\n",
        "\n",
        "      lloss_xy = torch.add(lx_loss, ly_loss)\n",
        "      lloss_wh = torch.add(lw_loss, lh_loss)\n",
        "      llocal_loss = torch.add(lloss_xy, lloss_wh)\n",
        "\n",
        "      #print('low_iou_loss_xy: ', lloss_xy)\n",
        "\n",
        "\n",
        "      if torch.isnan(llocal_loss).detach().any() == True:\n",
        "        llocal_loss = torch.zeros_like(llocal_loss)\n",
        "      #print('low_iou_loss_wh: ', lloss_wh)\n",
        "      #print('low_iou_loss: ', llocal_loss)\n",
        "      ltrue_object = torch.ones_like(low_iou_dict['true_confidence'])\n",
        "      if np.all(low_iou_dict['true_coord'][0].detach().numpy() == 0) == True and np.all(low_iou_dict['true_coord'][1].detach().numpy() == 0) == True and np.all(low_iou_dict['true_coord'][2].detach().numpy()==0) == True and np.all(low_iou_dict['true_coord'][3].detach().numpy()==0) == True:\n",
        "        ltrue_object = torch.zeros_like(low_iou_dict['true_confidence'])\n",
        "\n",
        "      lweighted_local_loss = torch.multiply(torch.multiply(llocal_loss, coord), ltrue_object)\n",
        "\n",
        "      #Confidence\n",
        "      hobj_confidence = torch.pow(torch.subtract(high_iou_dict['true_confidence'], high_iou_dict['pred_confidence']), 2)\n",
        "      hobj_confidence = torch.multiply(hobj_confidence, htrue_object)\n",
        "\n",
        "      hnoobj_confidence = torch.pow(torch.subtract(high_iou_dict['unresponsible']['true_confidence'], high_iou_dict['unresponsible']['pred_confidence']), 2)\n",
        "      hnoobj_confidence = torch.multiply(hnoobj_confidence, noobj)\n",
        "\n",
        "      lobj_confidence = torch.pow(torch.subtract(low_iou_dict['true_confidence'], low_iou_dict['pred_confidence']), 2)\n",
        "      lobj_confidence = torch.multiply(lobj_confidence, ltrue_object)\n",
        "\n",
        "      lnoobj_confidence = torch.pow(torch.subtract(low_iou_dict['unresponsible']['true_confidence'], low_iou_dict['unresponsible']['pred_confidence']), 2)\n",
        "      lnoobj_confidence = torch.multiply(lnoobj_confidence, noobj)\n",
        "\n",
        "      hconfidence_score_sum = torch.add(hobj_confidence, hnoobj_confidence)\n",
        "      lconfidence_score_sum = torch.add(lobj_confidence, lnoobj_confidence)\n",
        "\n",
        "      #Classification\n",
        "      class_loss = torch.pow(torch.subtract(true_class, pred_class), 2)\n",
        "      class_loss = torch.sum(class_loss)\n",
        "      hclass_loss = torch.multiply(class_loss, htrue_object)\n",
        "      lclass_loss = torch.multiply(class_loss, ltrue_object)\n",
        "\n",
        "      loss1 = torch.add(torch.add(hweighted_local_loss, hconfidence_score_sum), hclass_loss)\n",
        "      loss2 = torch.add(torch.add(lweighted_local_loss, lconfidence_score_sum), lclass_loss)\n",
        "      #print(\"loss1 : \", loss1)\n",
        "      #print(\"loss2 : \", loss2)\n",
        "      added_loss = torch.add(loss1, loss2)\n",
        "      sum_loss = torch.sum(added_loss)\n",
        "      sum_loss = sum_loss / 2\n",
        "      #print('added_loss: ', added_loss)\n",
        "      real_loss = added_loss[0]\n",
        "      #print('real_loss: ', real_loss)\n",
        "      #print('sum_loss: ', sum_loss)\n",
        "      #print('loss: ', loss)\n",
        "      if loss == 0:\n",
        "        loss = real_loss\n",
        "      else:\n",
        "        loss = loss + real_loss\n",
        "\n",
        "    if batch_loss == 0:\n",
        "      batch_loss = real_loss\n",
        "    else:\n",
        "      batch_loss = batch_loss + real_loss\n",
        "\n",
        "  batch_loss = batch_loss / count\n",
        "\n",
        "  return batch_loss\n"
      ],
      "metadata": {
        "id": "7yXN2fKcHI6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  batch_size = 32\n",
        "  epochs = 100\n",
        "  learning_rate = 1e-03\n",
        "  print(\"Data Downloading...\")\n",
        "  train_data = Pascal_data(root='voc_data/', year='2012', image_set='train', download=True)\n",
        "  test_data = Pascal_data(root='voc_data/', year='2012', image_set='val', download=True)\n",
        "  print(\"Successed\")\n",
        "  DataLoader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)\n",
        "  yolov1 = YOLOv1()\n",
        "  optimizer = torch.optim.Adam(yolov1.parameters(), lr=learning_rate)\n",
        "  train_result = train(yolov1, yolo_multitask_loss, optimizer, epochs, DataLoader)"
      ],
      "metadata": {
        "id": "twLoYbEmCgxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  batch_size = 8\n",
        "  epochs = 10\n",
        "  learning_rate = 1e-03\n",
        "  print(\"Data Downloading...\")\n",
        "  train_data = Pascal_data(root='voc_data/', year='2012', image_set='train', download=True)\n",
        "  test_data = Pascal_data(root='voc_data/', year='2012', image_set='val', download=True)\n",
        "  print(\"Successed\")\n",
        "  DataLoader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "cnIxawJRcbpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed5d171-df2e-4ed9-957b-86d03d97e960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Downloading...\n",
            "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to voc_data/VOCtrainval_11-May-2012.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1999639040/1999639040 [01:32<00:00, 21699907.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting voc_data/VOCtrainval_11-May-2012.tar to voc_data/\n",
            "Using downloaded and verified file: voc_data/VOCtrainval_11-May-2012.tar\n",
            "Extracting voc_data/VOCtrainval_11-May-2012.tar to voc_data/\n",
            "Successed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yolov1 = YOLOv1()"
      ],
      "metadata": {
        "id": "_ny_VBaazFVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(yolov1.parameters(), lr=learning_rate)\n",
        "train_result = train(yolov1, loss_fn, optimizer, epochs, DataLoader)"
      ],
      "metadata": {
        "id": "RZ2TgQ_Fzc47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4d7f06228238475db03f23be0f92ff57",
            "9f3e0d76e07e427488d6833289a9216b",
            "5db573aa165a4af18abb9e8787ba9aa1",
            "4fd4a8b0aa3d453386e55a347e0e8cce",
            "e4c41b2155d44a70862aa7a110f122bb",
            "21e74a05b04041d9a18a24ffd27f3dbf",
            "443cfa88d5bd4c2db86449575302c67f",
            "586ee40be1134431b6a9fb3b9aef69c8",
            "52adfc77f2e146f89518b996fef379b1",
            "68a023532b3f402eaf2911760cb0a9e5",
            "6e81bb29b5fe41058e83874298926ed9"
          ]
        },
        "outputId": "d0a64c74-7dd4-47f9-ae77-02bf9758c690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d7f06228238475db03f23be0f92ff57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d76c78a938a9>:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return transformed_img, torch.tensor(label)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repeat  10 / 714 \n",
            "loss:  48.029415130615234\n",
            "repeat  20 / 714 \n",
            "loss:  31.79925537109375\n",
            "repeat  30 / 714 \n",
            "loss:  38.77217483520508\n",
            "repeat  40 / 714 \n",
            "loss:  7.156322002410889\n",
            "repeat  50 / 714 \n",
            "loss:  0.6196203827857971\n",
            "repeat  60 / 714 \n",
            "loss:  1.644026756286621\n",
            "repeat  70 / 714 \n",
            "loss:  0.4743179678916931\n",
            "repeat  80 / 714 \n",
            "loss:  11.174866676330566\n",
            "repeat  90 / 714 \n",
            "loss:  40.1396598815918\n",
            "repeat  100 / 714 \n",
            "loss:  27.61166000366211\n",
            "repeat  110 / 714 \n",
            "loss:  21.60487174987793\n",
            "repeat  120 / 714 \n",
            "loss:  4.563792705535889\n",
            "repeat  130 / 714 \n",
            "loss:  31.43964385986328\n",
            "repeat  140 / 714 \n",
            "loss:  0.48479539155960083\n",
            "repeat  150 / 714 \n",
            "loss:  33.48288345336914\n",
            "repeat  160 / 714 \n",
            "loss:  9.706071853637695\n",
            "repeat  170 / 714 \n",
            "loss:  5.018853187561035\n",
            "repeat  180 / 714 \n",
            "loss:  42.302730560302734\n",
            "repeat  190 / 714 \n",
            "loss:  21.620220184326172\n",
            "repeat  200 / 714 \n",
            "loss:  8.84729290008545\n",
            "repeat  210 / 714 \n",
            "loss:  0.5073686242103577\n",
            "repeat  220 / 714 \n",
            "loss:  12.84506893157959\n",
            "repeat  230 / 714 \n",
            "loss:  4.926200866699219\n",
            "repeat  240 / 714 \n",
            "loss:  11.670049667358398\n",
            "repeat  250 / 714 \n",
            "loss:  18.586036682128906\n",
            "repeat  260 / 714 \n",
            "loss:  16.36517333984375\n",
            "repeat  270 / 714 \n",
            "loss:  34.828887939453125\n",
            "repeat  280 / 714 \n",
            "loss:  38.167823791503906\n",
            "repeat  290 / 714 \n",
            "loss:  9.935943603515625\n",
            "repeat  300 / 714 \n",
            "loss:  35.30804443359375\n",
            "repeat  310 / 714 \n",
            "loss:  9.74166488647461\n",
            "repeat  320 / 714 \n",
            "loss:  9.138799667358398\n",
            "repeat  330 / 714 \n",
            "loss:  7.429821491241455\n",
            "repeat  340 / 714 \n",
            "loss:  10.83990478515625\n",
            "repeat  350 / 714 \n",
            "loss:  6.5128865242004395\n",
            "repeat  360 / 714 \n",
            "loss:  22.222471237182617\n",
            "repeat  370 / 714 \n",
            "loss:  1.25187349319458\n",
            "repeat  380 / 714 \n",
            "loss:  26.810346603393555\n",
            "repeat  390 / 714 \n",
            "loss:  58.596832275390625\n",
            "repeat  400 / 714 \n",
            "loss:  19.761383056640625\n",
            "repeat  410 / 714 \n",
            "loss:  45.361812591552734\n",
            "repeat  420 / 714 \n",
            "loss:  51.410953521728516\n",
            "repeat  430 / 714 \n",
            "loss:  20.296903610229492\n",
            "repeat  440 / 714 \n",
            "loss:  4.007026195526123\n",
            "repeat  450 / 714 \n",
            "loss:  24.191259384155273\n",
            "repeat  460 / 714 \n",
            "loss:  0.9609788060188293\n",
            "repeat  470 / 714 \n",
            "loss:  26.63165283203125\n",
            "repeat  480 / 714 \n",
            "loss:  18.28806495666504\n",
            "repeat  490 / 714 \n",
            "loss:  30.152820587158203\n",
            "repeat  500 / 714 \n",
            "loss:  55.089698791503906\n",
            "repeat  510 / 714 \n",
            "loss:  0.4994024932384491\n",
            "repeat  520 / 714 \n",
            "loss:  0.7127934098243713\n",
            "repeat  530 / 714 \n",
            "loss:  18.19880485534668\n",
            "repeat  540 / 714 \n",
            "loss:  0.6532097458839417\n",
            "repeat  550 / 714 \n",
            "loss:  22.080753326416016\n",
            "repeat  560 / 714 \n",
            "loss:  0.5836371183395386\n",
            "repeat  570 / 714 \n",
            "loss:  0.5930212736129761\n",
            "repeat  580 / 714 \n",
            "loss:  18.340242385864258\n",
            "repeat  590 / 714 \n",
            "loss:  10.848832130432129\n",
            "repeat  600 / 714 \n",
            "loss:  3.5645763874053955\n",
            "repeat  610 / 714 \n",
            "loss:  19.07662582397461\n",
            "repeat  620 / 714 \n",
            "loss:  8.546860694885254\n",
            "repeat  630 / 714 \n",
            "loss:  20.322532653808594\n",
            "repeat  640 / 714 \n",
            "loss:  25.491588592529297\n",
            "repeat  650 / 714 \n",
            "loss:  24.005695343017578\n",
            "repeat  660 / 714 \n",
            "loss:  15.933470726013184\n",
            "repeat  670 / 714 \n",
            "loss:  4.865217208862305\n",
            "repeat  680 / 714 \n",
            "loss:  1.0130894184112549\n",
            "repeat  690 / 714 \n",
            "loss:  1.1248512268066406\n",
            "repeat  700 / 714 \n",
            "loss:  6.565541744232178\n",
            "repeat  710 / 714 \n",
            "loss:  1.4650726318359375\n",
            "Epoch: 1 | loss: 24.396297454833984\n",
            "repeat  10 / 714 \n",
            "loss:  19.920692443847656\n",
            "repeat  20 / 714 \n",
            "loss:  17.607946395874023\n",
            "repeat  30 / 714 \n",
            "loss:  12.677958488464355\n",
            "repeat  40 / 714 \n",
            "loss:  14.893132209777832\n",
            "repeat  50 / 714 \n",
            "loss:  16.250337600708008\n",
            "repeat  60 / 714 \n",
            "loss:  0.6699485778808594\n",
            "repeat  70 / 714 \n",
            "loss:  9.39604663848877\n",
            "repeat  80 / 714 \n",
            "loss:  0.4216369390487671\n",
            "repeat  90 / 714 \n",
            "loss:  24.3310546875\n",
            "repeat  100 / 714 \n",
            "loss:  0.9275597333908081\n",
            "repeat  110 / 714 \n",
            "loss:  0.6337894797325134\n",
            "repeat  120 / 714 \n",
            "loss:  44.8505859375\n",
            "repeat  130 / 714 \n",
            "loss:  4.236246585845947\n",
            "repeat  140 / 714 \n",
            "loss:  7.352340221405029\n",
            "repeat  150 / 714 \n",
            "loss:  0.9249457120895386\n",
            "repeat  160 / 714 \n",
            "loss:  11.038546562194824\n",
            "repeat  170 / 714 \n",
            "loss:  1.0630155801773071\n",
            "repeat  180 / 714 \n",
            "loss:  27.63268280029297\n",
            "repeat  190 / 714 \n",
            "loss:  26.823564529418945\n",
            "repeat  200 / 714 \n",
            "loss:  14.569225311279297\n",
            "repeat  210 / 714 \n",
            "loss:  17.029611587524414\n",
            "repeat  220 / 714 \n",
            "loss:  12.544384956359863\n",
            "repeat  230 / 714 \n",
            "loss:  17.097057342529297\n",
            "repeat  240 / 714 \n",
            "loss:  19.472427368164062\n",
            "repeat  250 / 714 \n",
            "loss:  1.223589539527893\n",
            "repeat  260 / 714 \n",
            "loss:  14.855426788330078\n",
            "repeat  270 / 714 \n",
            "loss:  27.309356689453125\n",
            "repeat  280 / 714 \n",
            "loss:  11.005650520324707\n",
            "repeat  290 / 714 \n",
            "loss:  0.9236611127853394\n",
            "repeat  300 / 714 \n",
            "loss:  0.317229688167572\n",
            "repeat  310 / 714 \n",
            "loss:  38.25114440917969\n",
            "repeat  320 / 714 \n",
            "loss:  0.616594135761261\n",
            "repeat  330 / 714 \n",
            "loss:  20.299333572387695\n",
            "repeat  340 / 714 \n",
            "loss:  16.410646438598633\n",
            "repeat  350 / 714 \n",
            "loss:  6.069764137268066\n",
            "repeat  360 / 714 \n",
            "loss:  0.860929012298584\n",
            "repeat  370 / 714 \n",
            "loss:  20.41896629333496\n",
            "repeat  380 / 714 \n",
            "loss:  0.27742186188697815\n",
            "repeat  390 / 714 \n",
            "loss:  24.214365005493164\n",
            "repeat  400 / 714 \n",
            "loss:  0.7709372639656067\n",
            "repeat  410 / 714 \n",
            "loss:  6.167888641357422\n",
            "repeat  420 / 714 \n",
            "loss:  38.03176498413086\n",
            "repeat  430 / 714 \n",
            "loss:  2.900343179702759\n",
            "repeat  440 / 714 \n",
            "loss:  14.179922103881836\n",
            "repeat  450 / 714 \n",
            "loss:  18.389034271240234\n",
            "repeat  460 / 714 \n",
            "loss:  17.733617782592773\n",
            "repeat  470 / 714 \n",
            "loss:  41.08489990234375\n",
            "repeat  480 / 714 \n",
            "loss:  1.0492353439331055\n",
            "repeat  490 / 714 \n",
            "loss:  4.8579421043396\n",
            "repeat  500 / 714 \n",
            "loss:  24.16911506652832\n",
            "repeat  510 / 714 \n",
            "loss:  1.104613184928894\n",
            "repeat  520 / 714 \n",
            "loss:  0.8770520687103271\n",
            "repeat  530 / 714 \n",
            "loss:  0.7673200368881226\n",
            "repeat  540 / 714 \n",
            "loss:  8.093661308288574\n",
            "repeat  550 / 714 \n",
            "loss:  3.4747812747955322\n",
            "repeat  560 / 714 \n",
            "loss:  0.42645299434661865\n",
            "repeat  570 / 714 \n",
            "loss:  18.145641326904297\n",
            "repeat  580 / 714 \n",
            "loss:  10.903911590576172\n",
            "repeat  590 / 714 \n",
            "loss:  26.22286605834961\n",
            "repeat  600 / 714 \n",
            "loss:  11.329642295837402\n",
            "repeat  610 / 714 \n",
            "loss:  0.6903107762336731\n",
            "repeat  620 / 714 \n",
            "loss:  41.55231857299805\n",
            "repeat  630 / 714 \n",
            "loss:  0.7035661935806274\n",
            "repeat  640 / 714 \n",
            "loss:  16.32566261291504\n",
            "repeat  650 / 714 \n",
            "loss:  0.883836030960083\n",
            "repeat  660 / 714 \n",
            "loss:  7.725517272949219\n",
            "repeat  670 / 714 \n",
            "loss:  17.865703582763672\n",
            "repeat  680 / 714 \n",
            "loss:  21.56474494934082\n",
            "repeat  690 / 714 \n",
            "loss:  63.7905158996582\n",
            "repeat  700 / 714 \n",
            "loss:  34.90217590332031\n",
            "repeat  710 / 714 \n",
            "loss:  13.99694538116455\n",
            "Epoch: 2 | loss: 0.6057026982307434\n",
            "repeat  10 / 714 \n",
            "loss:  0.9446669220924377\n",
            "repeat  20 / 714 \n",
            "loss:  0.5795863270759583\n",
            "repeat  30 / 714 \n",
            "loss:  3.3569557666778564\n",
            "repeat  40 / 714 \n",
            "loss:  6.678435802459717\n",
            "repeat  50 / 714 \n",
            "loss:  0.7864554524421692\n",
            "repeat  60 / 714 \n",
            "loss:  58.1317138671875\n",
            "repeat  70 / 714 \n",
            "loss:  9.388023376464844\n",
            "repeat  80 / 714 \n",
            "loss:  1.5263227224349976\n",
            "repeat  90 / 714 \n",
            "loss:  0.9800050258636475\n",
            "repeat  100 / 714 \n",
            "loss:  0.5752436518669128\n",
            "repeat  110 / 714 \n",
            "loss:  29.352880477905273\n",
            "repeat  120 / 714 \n",
            "loss:  13.791010856628418\n",
            "repeat  130 / 714 \n",
            "loss:  0.16284841299057007\n",
            "repeat  140 / 714 \n",
            "loss:  15.894914627075195\n",
            "repeat  150 / 714 \n",
            "loss:  0.4683836102485657\n",
            "repeat  160 / 714 \n",
            "loss:  0.4151175022125244\n",
            "repeat  170 / 714 \n",
            "loss:  30.835084915161133\n",
            "repeat  180 / 714 \n",
            "loss:  34.80430603027344\n",
            "repeat  190 / 714 \n",
            "loss:  18.18502426147461\n",
            "repeat  200 / 714 \n",
            "loss:  28.38694953918457\n",
            "repeat  210 / 714 \n",
            "loss:  10.89365291595459\n",
            "repeat  220 / 714 \n",
            "loss:  4.428607940673828\n",
            "repeat  230 / 714 \n",
            "loss:  0.5385977625846863\n",
            "repeat  240 / 714 \n",
            "loss:  9.284255981445312\n",
            "repeat  250 / 714 \n",
            "loss:  30.682514190673828\n",
            "repeat  260 / 714 \n",
            "loss:  69.98421478271484\n",
            "repeat  270 / 714 \n",
            "loss:  8.588054656982422\n",
            "repeat  280 / 714 \n",
            "loss:  5.864912986755371\n",
            "repeat  290 / 714 \n",
            "loss:  10.317131996154785\n",
            "repeat  300 / 714 \n",
            "loss:  1.1272094249725342\n",
            "repeat  310 / 714 \n",
            "loss:  18.248828887939453\n",
            "repeat  320 / 714 \n",
            "loss:  0.7283727526664734\n",
            "repeat  330 / 714 \n",
            "loss:  14.691157341003418\n",
            "repeat  340 / 714 \n",
            "loss:  12.158759117126465\n",
            "repeat  350 / 714 \n",
            "loss:  25.793987274169922\n",
            "repeat  360 / 714 \n",
            "loss:  12.275477409362793\n",
            "repeat  370 / 714 \n",
            "loss:  1.3970715999603271\n",
            "repeat  380 / 714 \n",
            "loss:  16.87165069580078\n",
            "repeat  390 / 714 \n",
            "loss:  26.208881378173828\n",
            "repeat  400 / 714 \n",
            "loss:  5.748913288116455\n",
            "repeat  410 / 714 \n",
            "loss:  0.5575029253959656\n",
            "repeat  420 / 714 \n",
            "loss:  0.7456077337265015\n",
            "repeat  430 / 714 \n",
            "loss:  19.126991271972656\n",
            "repeat  440 / 714 \n",
            "loss:  20.748470306396484\n",
            "repeat  450 / 714 \n",
            "loss:  4.182814121246338\n",
            "repeat  460 / 714 \n",
            "loss:  23.288949966430664\n",
            "repeat  470 / 714 \n",
            "loss:  6.8254876136779785\n",
            "repeat  480 / 714 \n",
            "loss:  46.356407165527344\n",
            "repeat  490 / 714 \n",
            "loss:  1.987385630607605\n",
            "repeat  500 / 714 \n",
            "loss:  16.3049259185791\n",
            "repeat  510 / 714 \n",
            "loss:  21.096120834350586\n",
            "repeat  520 / 714 \n",
            "loss:  25.517955780029297\n",
            "repeat  530 / 714 \n",
            "loss:  18.540613174438477\n",
            "repeat  540 / 714 \n",
            "loss:  0.46179378032684326\n",
            "repeat  550 / 714 \n",
            "loss:  11.366070747375488\n",
            "repeat  560 / 714 \n",
            "loss:  3.773668050765991\n",
            "repeat  570 / 714 \n",
            "loss:  36.84510040283203\n",
            "repeat  580 / 714 \n",
            "loss:  20.439247131347656\n",
            "repeat  590 / 714 \n",
            "loss:  1.3836661577224731\n",
            "repeat  600 / 714 \n",
            "loss:  6.290136814117432\n",
            "repeat  610 / 714 \n",
            "loss:  14.243097305297852\n",
            "repeat  620 / 714 \n",
            "loss:  6.2429704666137695\n",
            "repeat  630 / 714 \n",
            "loss:  29.233095169067383\n",
            "repeat  640 / 714 \n",
            "loss:  5.02255392074585\n",
            "repeat  650 / 714 \n",
            "loss:  25.6267032623291\n",
            "repeat  660 / 714 \n",
            "loss:  27.264739990234375\n",
            "repeat  670 / 714 \n",
            "loss:  6.786103248596191\n",
            "repeat  680 / 714 \n",
            "loss:  1.4846525192260742\n",
            "repeat  690 / 714 \n",
            "loss:  1.9915329217910767\n",
            "repeat  700 / 714 \n",
            "loss:  13.824636459350586\n",
            "repeat  710 / 714 \n",
            "loss:  25.713598251342773\n",
            "Epoch: 3 | loss: 0.5586097240447998\n",
            "repeat  10 / 714 \n",
            "loss:  4.836159706115723\n",
            "repeat  20 / 714 \n",
            "loss:  0.831092894077301\n",
            "repeat  30 / 714 \n",
            "loss:  6.196710586547852\n",
            "repeat  40 / 714 \n",
            "loss:  29.363616943359375\n",
            "repeat  50 / 714 \n",
            "loss:  0.6613419055938721\n",
            "repeat  60 / 714 \n",
            "loss:  5.3763108253479\n",
            "repeat  70 / 714 \n",
            "loss:  9.16837215423584\n",
            "repeat  80 / 714 \n",
            "loss:  7.902237415313721\n",
            "repeat  90 / 714 \n",
            "loss:  0.39458009600639343\n",
            "repeat  100 / 714 \n",
            "loss:  9.174337387084961\n",
            "repeat  110 / 714 \n",
            "loss:  1.127882719039917\n",
            "repeat  120 / 714 \n",
            "loss:  21.4166259765625\n",
            "repeat  130 / 714 \n",
            "loss:  33.745513916015625\n",
            "repeat  140 / 714 \n",
            "loss:  18.762632369995117\n",
            "repeat  150 / 714 \n",
            "loss:  9.16820240020752\n",
            "repeat  160 / 714 \n",
            "loss:  14.376289367675781\n",
            "repeat  170 / 714 \n",
            "loss:  0.48744431138038635\n",
            "repeat  180 / 714 \n",
            "loss:  3.610429525375366\n",
            "repeat  190 / 714 \n",
            "loss:  9.80201244354248\n",
            "repeat  200 / 714 \n",
            "loss:  13.909799575805664\n",
            "repeat  210 / 714 \n",
            "loss:  14.698123931884766\n",
            "repeat  220 / 714 \n",
            "loss:  9.450788497924805\n",
            "repeat  230 / 714 \n",
            "loss:  0.8140465617179871\n",
            "repeat  240 / 714 \n",
            "loss:  29.14043426513672\n",
            "repeat  250 / 714 \n",
            "loss:  32.32010269165039\n",
            "repeat  260 / 714 \n",
            "loss:  15.331281661987305\n",
            "repeat  270 / 714 \n",
            "loss:  12.828935623168945\n",
            "repeat  280 / 714 \n",
            "loss:  27.20616340637207\n",
            "repeat  290 / 714 \n",
            "loss:  16.91450309753418\n",
            "repeat  300 / 714 \n",
            "loss:  5.327301502227783\n",
            "repeat  310 / 714 \n",
            "loss:  0.6464489102363586\n",
            "repeat  320 / 714 \n",
            "loss:  25.40096092224121\n",
            "repeat  330 / 714 \n",
            "loss:  11.239801406860352\n",
            "repeat  340 / 714 \n",
            "loss:  1.1870914697647095\n",
            "repeat  350 / 714 \n",
            "loss:  9.836298942565918\n",
            "repeat  360 / 714 \n",
            "loss:  0.8758888244628906\n",
            "repeat  370 / 714 \n",
            "loss:  12.924217224121094\n",
            "repeat  380 / 714 \n",
            "loss:  0.41344591975212097\n",
            "repeat  390 / 714 \n",
            "loss:  1.147233486175537\n",
            "repeat  400 / 714 \n",
            "loss:  13.970148086547852\n",
            "repeat  410 / 714 \n",
            "loss:  4.130631446838379\n",
            "repeat  420 / 714 \n",
            "loss:  25.608095169067383\n",
            "repeat  430 / 714 \n",
            "loss:  21.580036163330078\n",
            "repeat  440 / 714 \n",
            "loss:  15.920499801635742\n",
            "repeat  450 / 714 \n",
            "loss:  4.63413667678833\n",
            "repeat  460 / 714 \n",
            "loss:  9.364604949951172\n",
            "repeat  470 / 714 \n",
            "loss:  8.846870422363281\n",
            "repeat  480 / 714 \n",
            "loss:  24.122190475463867\n",
            "repeat  490 / 714 \n",
            "loss:  23.6334285736084\n",
            "repeat  500 / 714 \n",
            "loss:  11.714232444763184\n",
            "repeat  510 / 714 \n",
            "loss:  1.117111086845398\n",
            "repeat  520 / 714 \n",
            "loss:  75.39159393310547\n",
            "repeat  530 / 714 \n",
            "loss:  13.726434707641602\n",
            "repeat  540 / 714 \n",
            "loss:  16.893051147460938\n",
            "repeat  550 / 714 \n",
            "loss:  15.509360313415527\n",
            "repeat  560 / 714 \n",
            "loss:  49.849029541015625\n",
            "repeat  570 / 714 \n",
            "loss:  28.32067108154297\n",
            "repeat  580 / 714 \n",
            "loss:  3.3695294857025146\n",
            "repeat  590 / 714 \n",
            "loss:  18.773597717285156\n",
            "repeat  600 / 714 \n",
            "loss:  1.0047638416290283\n",
            "repeat  610 / 714 \n",
            "loss:  13.78795337677002\n",
            "repeat  620 / 714 \n",
            "loss:  12.042696952819824\n",
            "repeat  630 / 714 \n",
            "loss:  12.413410186767578\n",
            "repeat  640 / 714 \n",
            "loss:  19.521575927734375\n",
            "repeat  650 / 714 \n",
            "loss:  29.039825439453125\n",
            "repeat  660 / 714 \n",
            "loss:  0.8497433662414551\n",
            "repeat  670 / 714 \n",
            "loss:  1.4414411783218384\n",
            "repeat  680 / 714 \n",
            "loss:  1.1636673212051392\n",
            "repeat  690 / 714 \n",
            "loss:  6.113821029663086\n",
            "repeat  700 / 714 \n",
            "loss:  0.5302577018737793\n",
            "repeat  710 / 714 \n",
            "loss:  10.23221492767334\n",
            "Epoch: 4 | loss: 20.20051383972168\n",
            "repeat  10 / 714 \n",
            "loss:  4.749314785003662\n",
            "repeat  20 / 714 \n",
            "loss:  5.340970039367676\n",
            "repeat  30 / 714 \n",
            "loss:  6.689958572387695\n",
            "repeat  40 / 714 \n",
            "loss:  17.350364685058594\n",
            "repeat  50 / 714 \n",
            "loss:  0.9953827857971191\n",
            "repeat  60 / 714 \n",
            "loss:  7.216870307922363\n",
            "repeat  70 / 714 \n",
            "loss:  68.08274841308594\n",
            "repeat  80 / 714 \n",
            "loss:  17.214080810546875\n",
            "repeat  90 / 714 \n",
            "loss:  27.213483810424805\n",
            "repeat  100 / 714 \n",
            "loss:  1.4075984954833984\n",
            "repeat  110 / 714 \n",
            "loss:  0.6988574266433716\n",
            "repeat  120 / 714 \n",
            "loss:  11.918116569519043\n",
            "repeat  130 / 714 \n",
            "loss:  0.8443828225135803\n",
            "repeat  140 / 714 \n",
            "loss:  16.135007858276367\n",
            "repeat  150 / 714 \n",
            "loss:  13.451294898986816\n",
            "repeat  160 / 714 \n",
            "loss:  5.249643802642822\n",
            "repeat  170 / 714 \n",
            "loss:  8.330389976501465\n",
            "repeat  180 / 714 \n",
            "loss:  9.52562427520752\n",
            "repeat  190 / 714 \n",
            "loss:  0.3713303208351135\n",
            "repeat  200 / 714 \n",
            "loss:  0.7783756852149963\n",
            "repeat  210 / 714 \n",
            "loss:  4.996280670166016\n",
            "repeat  220 / 714 \n",
            "loss:  4.137695789337158\n",
            "repeat  230 / 714 \n",
            "loss:  12.03194808959961\n",
            "repeat  240 / 714 \n",
            "loss:  8.365687370300293\n",
            "repeat  250 / 714 \n",
            "loss:  24.096338272094727\n",
            "repeat  260 / 714 \n",
            "loss:  2.976903200149536\n",
            "repeat  270 / 714 \n",
            "loss:  44.112300872802734\n",
            "repeat  280 / 714 \n",
            "loss:  3.9332449436187744\n",
            "repeat  290 / 714 \n",
            "loss:  7.841902256011963\n",
            "repeat  300 / 714 \n",
            "loss:  9.03821849822998\n",
            "repeat  310 / 714 \n",
            "loss:  0.5681402683258057\n",
            "repeat  320 / 714 \n",
            "loss:  1.148595929145813\n",
            "repeat  330 / 714 \n",
            "loss:  8.811429977416992\n",
            "repeat  340 / 714 \n",
            "loss:  0.6193473935127258\n",
            "repeat  350 / 714 \n",
            "loss:  49.742122650146484\n",
            "repeat  360 / 714 \n",
            "loss:  0.8788884282112122\n",
            "repeat  370 / 714 \n",
            "loss:  25.31751823425293\n",
            "repeat  380 / 714 \n",
            "loss:  0.8501272201538086\n",
            "repeat  390 / 714 \n",
            "loss:  19.507205963134766\n",
            "repeat  400 / 714 \n",
            "loss:  56.37313461303711\n",
            "repeat  410 / 714 \n",
            "loss:  0.520960807800293\n",
            "repeat  420 / 714 \n",
            "loss:  18.591997146606445\n",
            "repeat  430 / 714 \n",
            "loss:  0.8037850260734558\n",
            "repeat  440 / 714 \n",
            "loss:  10.055335998535156\n",
            "repeat  450 / 714 \n",
            "loss:  25.047576904296875\n",
            "repeat  460 / 714 \n",
            "loss:  15.934282302856445\n",
            "repeat  470 / 714 \n",
            "loss:  32.34906005859375\n",
            "repeat  480 / 714 \n",
            "loss:  17.382007598876953\n",
            "repeat  490 / 714 \n",
            "loss:  3.5917818546295166\n",
            "repeat  500 / 714 \n",
            "loss:  0.9945552349090576\n",
            "repeat  510 / 714 \n",
            "loss:  10.861580848693848\n",
            "repeat  520 / 714 \n",
            "loss:  18.366619110107422\n",
            "repeat  530 / 714 \n",
            "loss:  23.202749252319336\n",
            "repeat  540 / 714 \n",
            "loss:  13.030014991760254\n",
            "repeat  550 / 714 \n",
            "loss:  37.050025939941406\n",
            "repeat  560 / 714 \n",
            "loss:  6.622156143188477\n",
            "repeat  570 / 714 \n",
            "loss:  25.78849220275879\n",
            "repeat  580 / 714 \n",
            "loss:  11.602155685424805\n",
            "repeat  590 / 714 \n",
            "loss:  9.2533597946167\n",
            "repeat  600 / 714 \n",
            "loss:  14.391753196716309\n",
            "repeat  610 / 714 \n",
            "loss:  25.03590965270996\n",
            "repeat  620 / 714 \n",
            "loss:  4.9740800857543945\n",
            "repeat  630 / 714 \n",
            "loss:  1.0546550750732422\n",
            "repeat  640 / 714 \n",
            "loss:  7.05799674987793\n",
            "repeat  650 / 714 \n",
            "loss:  28.55665397644043\n",
            "repeat  660 / 714 \n",
            "loss:  10.67741584777832\n",
            "repeat  670 / 714 \n",
            "loss:  10.53759765625\n",
            "repeat  680 / 714 \n",
            "loss:  8.114377975463867\n",
            "repeat  690 / 714 \n",
            "loss:  0.597144365310669\n",
            "repeat  700 / 714 \n",
            "loss:  18.454984664916992\n",
            "repeat  710 / 714 \n",
            "loss:  14.960083961486816\n",
            "Epoch: 5 | loss: 0.4225238561630249\n",
            "repeat  10 / 714 \n",
            "loss:  3.765753984451294\n",
            "repeat  20 / 714 \n",
            "loss:  0.433567076921463\n",
            "repeat  30 / 714 \n",
            "loss:  0.838674783706665\n",
            "repeat  40 / 714 \n",
            "loss:  0.3418097198009491\n",
            "repeat  50 / 714 \n",
            "loss:  50.20986557006836\n",
            "repeat  60 / 714 \n",
            "loss:  8.409014701843262\n",
            "repeat  70 / 714 \n",
            "loss:  4.089319705963135\n",
            "repeat  80 / 714 \n",
            "loss:  58.04689407348633\n",
            "repeat  90 / 714 \n",
            "loss:  0.584255576133728\n",
            "repeat  100 / 714 \n",
            "loss:  0.7796069979667664\n",
            "repeat  110 / 714 \n",
            "loss:  27.94931983947754\n",
            "repeat  120 / 714 \n",
            "loss:  14.534600257873535\n",
            "repeat  130 / 714 \n",
            "loss:  0.4949192702770233\n",
            "repeat  140 / 714 \n",
            "loss:  19.54974365234375\n",
            "repeat  150 / 714 \n",
            "loss:  21.75463104248047\n",
            "repeat  160 / 714 \n",
            "loss:  15.052478790283203\n",
            "repeat  170 / 714 \n",
            "loss:  0.5732982158660889\n",
            "repeat  180 / 714 \n",
            "loss:  10.733232498168945\n",
            "repeat  190 / 714 \n",
            "loss:  0.8670611381530762\n",
            "repeat  200 / 714 \n",
            "loss:  0.4088152348995209\n",
            "repeat  210 / 714 \n",
            "loss:  0.8094830513000488\n",
            "repeat  220 / 714 \n",
            "loss:  0.8445318937301636\n",
            "repeat  230 / 714 \n",
            "loss:  20.037832260131836\n",
            "repeat  240 / 714 \n",
            "loss:  0.5331667065620422\n",
            "repeat  250 / 714 \n",
            "loss:  30.593324661254883\n",
            "repeat  260 / 714 \n",
            "loss:  29.99370574951172\n",
            "repeat  270 / 714 \n",
            "loss:  20.87761116027832\n",
            "repeat  280 / 714 \n",
            "loss:  3.869206190109253\n",
            "repeat  290 / 714 \n",
            "loss:  8.51906681060791\n",
            "repeat  300 / 714 \n",
            "loss:  16.89632797241211\n",
            "repeat  310 / 714 \n",
            "loss:  13.730058670043945\n",
            "repeat  320 / 714 \n",
            "loss:  0.39802277088165283\n",
            "repeat  330 / 714 \n",
            "loss:  18.1856746673584\n",
            "repeat  340 / 714 \n",
            "loss:  41.048728942871094\n",
            "repeat  350 / 714 \n",
            "loss:  41.192649841308594\n",
            "repeat  360 / 714 \n",
            "loss:  32.817901611328125\n",
            "repeat  370 / 714 \n",
            "loss:  23.590007781982422\n",
            "repeat  380 / 714 \n",
            "loss:  8.63357925415039\n",
            "repeat  390 / 714 \n",
            "loss:  4.685299873352051\n",
            "repeat  400 / 714 \n",
            "loss:  0.313869833946228\n",
            "repeat  410 / 714 \n",
            "loss:  10.685958862304688\n",
            "repeat  420 / 714 \n",
            "loss:  0.7424985766410828\n",
            "repeat  430 / 714 \n",
            "loss:  17.703147888183594\n",
            "repeat  440 / 714 \n",
            "loss:  22.280685424804688\n",
            "repeat  450 / 714 \n",
            "loss:  0.7988123893737793\n",
            "repeat  460 / 714 \n",
            "loss:  0.9205681085586548\n",
            "repeat  470 / 714 \n",
            "loss:  4.61340856552124\n",
            "repeat  480 / 714 \n",
            "loss:  15.266225814819336\n",
            "repeat  490 / 714 \n",
            "loss:  0.36780720949172974\n",
            "repeat  500 / 714 \n",
            "loss:  4.504637241363525\n",
            "repeat  510 / 714 \n",
            "loss:  0.5446217060089111\n",
            "repeat  520 / 714 \n",
            "loss:  16.077119827270508\n",
            "repeat  530 / 714 \n",
            "loss:  26.355655670166016\n",
            "repeat  540 / 714 \n",
            "loss:  0.8779786229133606\n",
            "repeat  550 / 714 \n",
            "loss:  5.169139862060547\n",
            "repeat  560 / 714 \n",
            "loss:  5.325135231018066\n",
            "repeat  570 / 714 \n",
            "loss:  35.96076202392578\n",
            "repeat  580 / 714 \n",
            "loss:  0.9487370848655701\n",
            "repeat  590 / 714 \n",
            "loss:  19.346691131591797\n",
            "repeat  600 / 714 \n",
            "loss:  28.729877471923828\n",
            "repeat  610 / 714 \n",
            "loss:  15.326092720031738\n",
            "repeat  620 / 714 \n",
            "loss:  0.7521826028823853\n",
            "repeat  630 / 714 \n",
            "loss:  30.022918701171875\n",
            "repeat  640 / 714 \n",
            "loss:  14.761053085327148\n",
            "repeat  650 / 714 \n",
            "loss:  19.87410545349121\n",
            "repeat  660 / 714 \n",
            "loss:  7.897349834442139\n",
            "repeat  670 / 714 \n",
            "loss:  47.29336929321289\n",
            "repeat  680 / 714 \n",
            "loss:  69.0123519897461\n",
            "repeat  690 / 714 \n",
            "loss:  24.91579818725586\n",
            "repeat  700 / 714 \n",
            "loss:  19.466358184814453\n",
            "repeat  710 / 714 \n",
            "loss:  4.911304473876953\n",
            "Epoch: 6 | loss: 13.586060523986816\n",
            "repeat  10 / 714 \n",
            "loss:  0.5036152005195618\n",
            "repeat  20 / 714 \n",
            "loss:  22.305980682373047\n",
            "repeat  30 / 714 \n",
            "loss:  60.20176696777344\n",
            "repeat  40 / 714 \n",
            "loss:  7.481964111328125\n",
            "repeat  50 / 714 \n",
            "loss:  15.156414031982422\n",
            "repeat  60 / 714 \n",
            "loss:  13.716285705566406\n",
            "repeat  70 / 714 \n",
            "loss:  0.94740229845047\n",
            "repeat  80 / 714 \n",
            "loss:  24.18598747253418\n",
            "repeat  90 / 714 \n",
            "loss:  14.978678703308105\n",
            "repeat  100 / 714 \n",
            "loss:  16.574115753173828\n",
            "repeat  110 / 714 \n",
            "loss:  8.324444770812988\n",
            "repeat  120 / 714 \n",
            "loss:  67.75688934326172\n",
            "repeat  130 / 714 \n",
            "loss:  17.18903350830078\n",
            "repeat  140 / 714 \n",
            "loss:  0.672945499420166\n",
            "repeat  150 / 714 \n",
            "loss:  27.05036163330078\n",
            "repeat  160 / 714 \n",
            "loss:  0.583350419998169\n",
            "repeat  170 / 714 \n",
            "loss:  10.221663475036621\n",
            "repeat  180 / 714 \n",
            "loss:  26.0286922454834\n",
            "repeat  190 / 714 \n",
            "loss:  36.678489685058594\n",
            "repeat  200 / 714 \n",
            "loss:  19.23381233215332\n",
            "repeat  210 / 714 \n",
            "loss:  23.605592727661133\n",
            "repeat  220 / 714 \n",
            "loss:  34.92686080932617\n",
            "repeat  230 / 714 \n",
            "loss:  7.273602485656738\n",
            "repeat  240 / 714 \n",
            "loss:  9.922524452209473\n",
            "repeat  250 / 714 \n",
            "loss:  17.08400535583496\n",
            "repeat  260 / 714 \n",
            "loss:  12.643427848815918\n",
            "repeat  270 / 714 \n",
            "loss:  5.956935882568359\n",
            "repeat  280 / 714 \n",
            "loss:  0.7222251296043396\n",
            "repeat  290 / 714 \n",
            "loss:  5.968514442443848\n",
            "repeat  300 / 714 \n",
            "loss:  16.625633239746094\n",
            "repeat  310 / 714 \n",
            "loss:  9.35741901397705\n",
            "repeat  320 / 714 \n",
            "loss:  20.412750244140625\n",
            "repeat  330 / 714 \n",
            "loss:  0.8646195530891418\n",
            "repeat  340 / 714 \n",
            "loss:  11.51054859161377\n",
            "repeat  350 / 714 \n",
            "loss:  17.855403900146484\n",
            "repeat  360 / 714 \n",
            "loss:  7.857058525085449\n",
            "repeat  370 / 714 \n",
            "loss:  0.66756272315979\n",
            "repeat  380 / 714 \n",
            "loss:  0.8450940847396851\n",
            "repeat  390 / 714 \n",
            "loss:  0.8173052668571472\n",
            "repeat  400 / 714 \n",
            "loss:  16.71164894104004\n",
            "repeat  410 / 714 \n",
            "loss:  16.724468231201172\n",
            "repeat  420 / 714 \n",
            "loss:  43.51154327392578\n",
            "repeat  430 / 714 \n",
            "loss:  14.971670150756836\n",
            "repeat  440 / 714 \n",
            "loss:  0.5739544034004211\n",
            "repeat  450 / 714 \n",
            "loss:  20.545114517211914\n",
            "repeat  460 / 714 \n",
            "loss:  15.931647300720215\n",
            "repeat  470 / 714 \n",
            "loss:  0.4396393299102783\n",
            "repeat  480 / 714 \n",
            "loss:  16.4317626953125\n",
            "repeat  490 / 714 \n",
            "loss:  20.16559600830078\n",
            "repeat  500 / 714 \n",
            "loss:  0.6292642951011658\n",
            "repeat  510 / 714 \n",
            "loss:  10.254265785217285\n",
            "repeat  520 / 714 \n",
            "loss:  6.632094860076904\n",
            "repeat  530 / 714 \n",
            "loss:  14.203396797180176\n",
            "repeat  540 / 714 \n",
            "loss:  46.984439849853516\n",
            "repeat  550 / 714 \n",
            "loss:  7.000758647918701\n",
            "repeat  560 / 714 \n",
            "loss:  13.841333389282227\n",
            "repeat  570 / 714 \n",
            "loss:  8.586166381835938\n",
            "repeat  580 / 714 \n",
            "loss:  0.5965344309806824\n",
            "repeat  590 / 714 \n",
            "loss:  0.8563604950904846\n",
            "repeat  600 / 714 \n",
            "loss:  9.174738883972168\n",
            "repeat  610 / 714 \n",
            "loss:  12.518157005310059\n",
            "repeat  620 / 714 \n",
            "loss:  22.482288360595703\n",
            "repeat  630 / 714 \n",
            "loss:  0.6877472400665283\n",
            "repeat  640 / 714 \n",
            "loss:  32.424957275390625\n",
            "repeat  650 / 714 \n",
            "loss:  9.010625839233398\n",
            "repeat  660 / 714 \n",
            "loss:  8.531074523925781\n",
            "repeat  670 / 714 \n",
            "loss:  7.683786392211914\n",
            "repeat  680 / 714 \n",
            "loss:  40.70448303222656\n",
            "repeat  690 / 714 \n",
            "loss:  0.8002298474311829\n",
            "repeat  700 / 714 \n",
            "loss:  26.70671272277832\n",
            "repeat  710 / 714 \n",
            "loss:  15.360151290893555\n",
            "Epoch: 7 | loss: 11.218655586242676\n",
            "repeat  10 / 714 \n",
            "loss:  0.644951581954956\n",
            "repeat  20 / 714 \n",
            "loss:  1.0558091402053833\n",
            "repeat  30 / 714 \n",
            "loss:  35.49304962158203\n",
            "repeat  40 / 714 \n",
            "loss:  0.8363901376724243\n",
            "repeat  50 / 714 \n",
            "loss:  0.6281648278236389\n",
            "repeat  60 / 714 \n",
            "loss:  9.546224594116211\n",
            "repeat  70 / 714 \n",
            "loss:  26.873821258544922\n",
            "repeat  80 / 714 \n",
            "loss:  4.304045677185059\n",
            "repeat  90 / 714 \n",
            "loss:  0.5735070109367371\n",
            "repeat  100 / 714 \n",
            "loss:  5.468128681182861\n",
            "repeat  110 / 714 \n",
            "loss:  15.932400703430176\n",
            "repeat  120 / 714 \n",
            "loss:  4.191804885864258\n",
            "repeat  130 / 714 \n",
            "loss:  11.062898635864258\n",
            "repeat  140 / 714 \n",
            "loss:  13.11802864074707\n",
            "repeat  150 / 714 \n",
            "loss:  0.5849312543869019\n",
            "repeat  160 / 714 \n",
            "loss:  13.177928924560547\n",
            "repeat  170 / 714 \n",
            "loss:  10.694766998291016\n",
            "repeat  180 / 714 \n",
            "loss:  14.4544038772583\n",
            "repeat  190 / 714 \n",
            "loss:  0.7418941855430603\n",
            "repeat  200 / 714 \n",
            "loss:  4.939953804016113\n",
            "repeat  210 / 714 \n",
            "loss:  23.55631446838379\n",
            "repeat  220 / 714 \n",
            "loss:  5.168825626373291\n",
            "repeat  230 / 714 \n",
            "loss:  0.6069361567497253\n",
            "repeat  240 / 714 \n",
            "loss:  13.073272705078125\n",
            "repeat  250 / 714 \n",
            "loss:  8.223923683166504\n",
            "repeat  260 / 714 \n",
            "loss:  19.742097854614258\n",
            "repeat  270 / 714 \n",
            "loss:  67.18994140625\n",
            "repeat  280 / 714 \n",
            "loss:  0.5215667486190796\n",
            "repeat  290 / 714 \n",
            "loss:  19.81667709350586\n",
            "repeat  300 / 714 \n",
            "loss:  8.558723449707031\n"
          ]
        }
      ]
    }
  ]
}